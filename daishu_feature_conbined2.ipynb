{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S4_feature_conbined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import gc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_target(x): # ここに渡すoof, subはgroupby(\"customer_ID\")もしてない(->customer_IDによって1~13レコード、数がバラバラ) --\n",
    "    t = np.zeros(13)\n",
    "    t[:-len(x)] = np.nan\n",
    "    t[-len(x):] = x\n",
    "    return list(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = pd.read_csv(\"./output/LGB_with_series_feature/oof.csv\")\n",
    "sub = pd.read_csv(\"./output/LGB_with_series_feature/submission.csv\")\n",
    "\n",
    "tmp1 = oof.groupby(\"customer_ID\", sort=False)[\"target\"].agg(lambda x: pad_target(x))\n",
    "tmp2 = sub.groupby(\"customer_ID\", sort=False)[\"prediction\"].agg(lambda x: pad_target(x))\n",
    "\n",
    "tmp = tmp1.append(tmp2)\n",
    "tmp = pd.DataFrame(data=tmp.tolist(), columns=[\"target%s\"%i for i in range(1, 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del oof, sub, tmp1, tmp2; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GreedyFindBin(distinct_values, counts,num_distinct_values, max_bin, total_cnt, min_data_in_bin=3):\n",
    "#INPUT:\n",
    "#   distinct_values 保存特征取值的数组，特征取值单调递增\n",
    "#   counts 特征的取值对应的样本数目\n",
    "#   num_distinct_values 特征取值的数量\n",
    "#   max_bin 分桶的最大数量\n",
    "#   total_cnt 样本数量\n",
    "#   min_data_in_bin 桶包含的最小样本数\n",
    "\n",
    "# bin_upper_bound就是记录桶分界的数组\n",
    "    bin_upper_bound=list();\n",
    "    assert(max_bin>0)\n",
    "\n",
    "    # 特征取值数比max_bin数量少，直接取distinct_values的中点放置\n",
    "    if num_distinct_values <= max_bin:\n",
    "        cur_cnt_inbin = 0\n",
    "        for i in range(num_distinct_values-1):\n",
    "            cur_cnt_inbin += counts[i]\n",
    "            #若一个特征的取值比min_data_in_bin小，则累积下一个取值，直到比min_data_in_bin大，进入循环。\n",
    "            if cur_cnt_inbin >= min_data_in_bin:\n",
    "                #取当前值和下一个值的均值作为该桶的分界点bin_upper_bound\n",
    "                bin_upper_bound.append((distinct_values[i] + distinct_values[i + 1]) / 2.0)\n",
    "                cur_cnt_inbin = 0\n",
    "        # 对于最后一个桶的上界则为无穷大\n",
    "        cur_cnt_inbin += counts[num_distinct_values - 1];\n",
    "        bin_upper_bound.append(float('Inf'))\n",
    "        # 特征取值数比max_bin来得大，说明几个特征值要共用一个bin\n",
    "    else:\n",
    "        if min_data_in_bin>0:\n",
    "            max_bin=min(max_bin,total_cnt//min_data_in_bin)\n",
    "            max_bin=max(max_bin,1)\n",
    "        #mean size for one bin\n",
    "        mean_bin_size=total_cnt/max_bin\n",
    "        rest_bin_cnt = max_bin\n",
    "        rest_sample_cnt = total_cnt\n",
    "        #定义is_big_count_value数组：初始设定特征每一个不同的值的数量都小（false）\n",
    "        is_big_count_value=[False]*num_distinct_values\n",
    "        #如果一个特征值的数目比mean_bin_size大，那么这些特征需要单独一个bin\n",
    "        for i in range(num_distinct_values):\n",
    "        #如果一个特征值的数目比mean_bin_size大，则设定这个特征值对应的is_big_count_value为真。。\n",
    "            if counts[i] >= mean_bin_size:\n",
    "                is_big_count_value[i] = True\n",
    "                rest_bin_cnt-=1\n",
    "                rest_sample_cnt -= counts[i]\n",
    "        #剩下的特征取值的样本数平均每个剩下的bin：mean size for one bin\n",
    "        mean_bin_size = rest_sample_cnt/rest_bin_cnt\n",
    "        upper_bounds=[float('Inf')]*max_bin\n",
    "        lower_bounds=[float('Inf')]*max_bin\n",
    "\n",
    "        bin_cnt = 0\n",
    "        lower_bounds[bin_cnt] = distinct_values[0]\n",
    "        cur_cnt_inbin = 0\n",
    "        #重新遍历所有的特征值（包括数目大和数目小的）\n",
    "        for i in range(num_distinct_values-1):\n",
    "            #如果当前的特征值数目是小的\n",
    "            if not is_big_count_value[i]:\n",
    "                rest_sample_cnt -= counts[i]\n",
    "            cur_cnt_inbin += counts[i]\n",
    "\n",
    "            # 若cur_cnt_inbin太少，则累积下一个取值，直到满足条件，进入循环。\n",
    "            # need a new bin 当前的特征如果是需要单独成一个bin，或者当前几个特征计数超过了mean_bin_size，或者下一个是需要独立成桶的\n",
    "            if is_big_count_value[i] or cur_cnt_inbin >= mean_bin_size or \\\n",
    "            is_big_count_value[i + 1] and cur_cnt_inbin >= max(1.0, mean_bin_size * 0.5):\n",
    "                upper_bounds[bin_cnt] = distinct_values[i] # 第i个bin的最大就是 distinct_values[i]了\n",
    "                bin_cnt+=1\n",
    "                lower_bounds[bin_cnt] = distinct_values[i + 1] # 下一个bin的最小就是distinct_values[i + 1]，注意先++bin了\n",
    "                if bin_cnt >= max_bin - 1:\n",
    "                    break\n",
    "                cur_cnt_inbin = 0\n",
    "                if not is_big_count_value[i]:\n",
    "                    rest_bin_cnt-=1\n",
    "                    mean_bin_size = rest_sample_cnt / rest_bin_cnt\n",
    "#             bin_cnt+=1\n",
    "        # update bin upper bound 与特征取值数比max_bin数量少的操作类似，取当前值和下一个值的均值作为该桶的分界点\n",
    "        for i in range(bin_cnt-1):\n",
    "            bin_upper_bound.append((upper_bounds[i] + lower_bounds[i + 1]) / 2.0)\n",
    "        bin_upper_bound.append(float('Inf'))\n",
    "    return bin_upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [00:14<00:00, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 594.33 MB\n",
      "Decreased by 73.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1062/1062 [03:13<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2802.49 MB\n",
      "Decreased by 75.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1062/1062 [02:34<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2802.49 MB\n",
      "Decreased by 75.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [00:10<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 467.08 MB\n",
      "Decreased by 75.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:05<00:00, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 395.83 MB\n",
      "Decreased by 75.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 885/885 [01:48<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2335.41 MB\n",
      "Decreased by 75.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 885/885 [02:12<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2335.41 MB\n",
      "Decreased by 75.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 885/885 [02:12<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2335.41 MB\n",
      "Decreased by 75.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1062/1062 [04:41<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2802.49 MB\n",
      "Decreased by 75.0%\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for fn in [\"cat\", \"num\", \"diff\", \"rank_num\", \"last3_cat\", \"last3_num\", \"last3_diff\", \"last6_num\", \"ym_rank_num\"]:\n",
    "    if len(dfs) == 0:\n",
    "        dfs.append(pd.read_feather(f\"./input/{fn}_feature.feather\"))\n",
    "    else:\n",
    "        dfs.append(pd.read_feather(f\"./input/{fn}_feature.feather\").drop([\"customer_ID\"], axis=1))\n",
    "\n",
    "    if \"last\" in fn:\n",
    "        dfs[-1] = dfs[-1].add_prefix(\"_\".join(fn.split(\"_\")[:-1])+\"_\")\n",
    "\n",
    "for df in dfs:\n",
    "    for col in tqdm(df.columns):\n",
    "        if col not in ['customer_ID','S_2']:\n",
    "            # v_min = df[col].min()\n",
    "            # v_max = df[col].max()\n",
    "            # df[col] = (df[col]-v_min+eps) / (v_max-v_min+eps)\n",
    "            vc = df[col].value_counts().sort_index()\n",
    "            bins = GreedyFindBin(vc.index.values,vc.values,len(vc),255,vc.sum())\n",
    "            df[col] = np.digitize(df[col],[-np.inf]+bins)\n",
    "            df.loc[df[col]==len(bins)+1,col] = 0\n",
    "            df[col] = df[col] / df[col].max()\n",
    "\n",
    "    # rmu\n",
    "    df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.fillna(0)\n",
    "dfs.append(tmp)\n",
    "df = pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(\"./input/nn_all_feature.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = tmp[\"target1\"].value_counts().sort_index()\n",
    "\n",
    "tt = GreedyFindBin(vc.index.values, vc.values, len(vc), 255, vc.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.909507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.919612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.930805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.943475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.000016\n",
       "1    0.000239\n",
       "2    0.000309\n",
       "3    0.000366\n",
       "4    0.000417\n",
       "..        ...\n",
       "249  0.909507\n",
       "250  0.919612\n",
       "251  0.930805\n",
       "252  0.943475\n",
       "253       inf\n",
       "\n",
       "[254 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = pd.DataFrame(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c90c4efae355953581131fe5eb685f809605ddb2abb7edf8826c72b30e930c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
