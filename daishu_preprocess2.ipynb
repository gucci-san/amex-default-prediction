{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available gpus: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_feature: 100%|██████████| 16/16 [01:40<00:00,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86471, 1063)\n",
      "num feature shape after engineering (86469, 1063)\n",
      "Memory usage after optimization is: 2850.58 MB\n",
      "Decreased by 74.6%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc,os,random\n",
    "import time,datetime\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool as ThreadPool\n",
    "\n",
    "from utils import reduce_mem_usage\n",
    "\n",
    "def one_hot_encoding(df,cols,is_drop=True):\n",
    "    for col in cols:\n",
    "        print('one hot encoding:',col)\n",
    "        dummies = pd.get_dummies(pd.Series(df[col]),prefix='oneHot_%s'%col)\n",
    "        df = pd.concat([df,dummies],axis=1)\n",
    "    if is_drop:\n",
    "        df.drop(cols,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def cat_feature(df):\n",
    "    one_hot_features = [col for col in df.columns if 'oneHot' in col]\n",
    "    if lastk is None:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[one_hot_features].agg(['mean', 'std', 'sum', 'last'])\n",
    "    else:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[one_hot_features].agg(['mean', 'std', 'sum'])\n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "\n",
    "    # ここは1st place solutionの投稿には書いてない（featurization - category - last, nuniqueはないので --\n",
    "    if lastk is None:\n",
    "        cat_agg_df = df.groupby(\"customer_ID\",sort=False)[cat_features].agg(['last', 'nunique'])\n",
    "    else:\n",
    "        cat_agg_df = df.groupby(\"customer_ID\",sort=False)[cat_features].agg(['nunique'])\n",
    "    cat_agg_df.columns = ['_'.join(x) for x in cat_agg_df.columns]\n",
    "\n",
    "    count_agg_df = df.groupby(\"customer_ID\",sort=False)[['S_2']].agg(['count'])\n",
    "    count_agg_df.columns = ['_'.join(x) for x in count_agg_df.columns]\n",
    "    df = pd.concat([num_agg_df, cat_agg_df,count_agg_df], axis=1).reset_index()\n",
    "    print('cat feature shape after engineering', df.shape )\n",
    "\n",
    "    return df\n",
    "\n",
    "def num_feature(df):\n",
    "    if num_features[0][:5] == 'rank_':\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['last'])\n",
    "    else:\n",
    "        if lastk is None:\n",
    "            num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['mean', 'std', 'min', 'max', 'sum', 'last'])\n",
    "        else:\n",
    "            num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['mean', 'std', 'min', 'max', 'sum'])\n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "    if num_features[0][:5] != 'rank_':\n",
    "        for col in num_agg_df.columns:\n",
    "            num_agg_df[col] = num_agg_df[col] // 0.01\n",
    "    df = num_agg_df.reset_index()\n",
    "    print('num feature shape after engineering', df.shape )\n",
    "\n",
    "    return df\n",
    "\n",
    "def diff_feature(df):\n",
    "    diff_num_features = [f'diff_{col}' for col in num_features]\n",
    "    cids = df['customer_ID'].values\n",
    "    df = df.groupby('customer_ID')[num_features].diff().add_prefix('diff_')\n",
    "    df.insert(0,'customer_ID',cids)\n",
    "    if lastk is None:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[diff_num_features].agg(['mean', 'std', 'min', 'max', 'sum', 'last'])\n",
    "    else:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[diff_num_features].agg(['mean', 'std', 'min', 'max', 'sum'])\n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "    for col in num_agg_df.columns:\n",
    "        num_agg_df[col] = num_agg_df[col] // 0.01\n",
    "\n",
    "    df = num_agg_df.reset_index()\n",
    "    print('diff feature shape after engineering', df.shape )\n",
    "\n",
    "    return df\n",
    "\n",
    "n_cpu = 16\n",
    "transform = [['','rank_','ym_rank_'],[''],['']]\n",
    "\n",
    "lastk = None # [None, 3, 6] --\n",
    "prefix = \"ym_rank_\"  # [[\"\", \"rank_\", \"ym_rank_\"], [\"\"], [\"\"]] --\n",
    "\n",
    "df = pd.read_feather(f'./input/train_denoise.feather').append(pd.read_feather(f'./input/test_denoise.feather')).reset_index(drop=True)\n",
    "all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "num_features = [col for col in all_cols if col not in cat_features]\n",
    "for col in [col for col in df.columns if 'S_' in col or 'P_' in col]:\n",
    "    if col != 'S_2':\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "if lastk is not None:\n",
    "    prefix = f'last{lastk}_' + prefix\n",
    "    print('all df shape',df.shape)\n",
    "    df['rank'] = df.groupby('customer_ID')['S_2'].rank(ascending=False)\n",
    "    df = df.loc[df['rank']<=lastk].reset_index(drop=True)\n",
    "    df = df.drop(['rank'],axis=1)\n",
    "    print(f'last {lastk} shape',df.shape)\n",
    "\n",
    "if prefix == 'rank_':\n",
    "    cids = df['customer_ID'].values\n",
    "    df = df.groupby('customer_ID')[num_features].rank(pct=True).add_prefix('rank_')\n",
    "    df.insert(0,'customer_ID',cids)\n",
    "    num_features = [f'rank_{col}' for col in num_features]\n",
    "\n",
    "if prefix == 'ym_rank_':\n",
    "    cids = df['customer_ID'].values\n",
    "    df['ym'] = df['S_2'].apply(lambda x:x[:7])\n",
    "    df = df.groupby('ym')[num_features].rank(pct=True).add_prefix('ym_rank_')\n",
    "    num_features = [f'ym_rank_{col}' for col in num_features]\n",
    "    df.insert(0,'customer_ID',cids)\n",
    "\n",
    "if prefix in ['','last3_']:\n",
    "    df = one_hot_encoding(df,cat_features,False)\n",
    "\n",
    "vc = df['customer_ID'].value_counts(sort=False).cumsum()\n",
    "batch_size = int(np.ceil(len(vc) / n_cpu))\n",
    "dfs = []\n",
    "start = 0\n",
    "for i in range(min(n_cpu,int(np.ceil(len(vc) / batch_size)))):\n",
    "    vc_ = vc[i*batch_size:(i+1)*batch_size]\n",
    "    dfs.append(df[start:vc_[-1]])\n",
    "    start = vc_[-1]\n",
    "\n",
    "del df; gc.collect()\n",
    "\n",
    "pool = ThreadPool(n_cpu)\n",
    "\n",
    "if prefix in ['','last3_']:\n",
    "    cat_feature_df = pd.concat(pool.map(cat_feature,tqdm(dfs,desc='cat_feature'))).reset_index(drop=True)\n",
    "    cat_feature_df = reduce_mem_usage(cat_feature_df)         \n",
    "    cat_feature_df.to_feather(f'./input/{prefix}cat_feature.feather')\n",
    "    del cat_feature_df; gc.collect()\n",
    "\n",
    "if prefix in ['','last3_','last6_','rank_','ym_rank_']:\n",
    "    num_feature_df = pd.concat(pool.map(num_feature,tqdm(dfs,desc='num_feature'))).reset_index(drop=True)\n",
    "    num_feature_df = reduce_mem_usage(num_feature_df)\n",
    "    num_feature_df.to_feather(f'./input/{prefix}num_feature.feather')\n",
    "    del num_feature_df; gc.collect()\n",
    "\n",
    "if prefix in ['','last3_']:\n",
    "    diff_feature_df = pd.concat(pool.map(diff_feature,tqdm(dfs,desc='diff_feature'))).reset_index(drop=True)\n",
    "    diff_feature_df = reduce_mem_usage(diff_feature_df)\n",
    "    diff_feature_df.to_feather(f'./input/{prefix}diff_feature.feather')\n",
    "    del diff_feature_df; gc.collect()\n",
    "\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c90c4efae355953581131fe5eb685f809605ddb2abb7edf8826c72b30e930c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
